Stable Diffusion 与 GPT-3(.5) 和 GPT-4 等 AI 模型正在改变网络生态。如果人类消费的大部分内容是 AI 生成的，那么 AI 又如何继续改进其模型呢？如果 AI 用 AI 生成的数据进行训练又会发生什么？牛津、剑桥、伦敦帝国学院等机构的研究人员在预印本平台 arXiv 上发表论文，对此展开了分析。研究人员发现，这会导致 AI 模型存在不可逆转的缺陷，他们将其称之为 __模型崩溃__（Model Collapse）。这意味着未来模型训练使用的高质量数据将会愈来愈昂贵，将可能导致网络的碎片化和封闭化，内容创作者将会竭尽全力防止其内容被免费抓取。社交媒体公司也逐渐认识到其数据的价值，对 API 访问收取昂贵费用。如果未来的模型使用容易获取的数据（很可能是其它模型生成）训练，那么这将会加速模型的崩溃，增加对模型进行中毒攻击的可能性。